---
knit: "bookdown::render_book"
---

# 05: Probabilidade condicional (continuação) {-}

## Vídeo {-}

```{r echo=FALSE, results='asis', out.extra=center()}
embed_yt('JzDvVgNDxo8')
```


## Exercícios do livro (cap. 2) {-}

### 30 {-}

::: {.rmdbox latex=1}

Uma família tem $3$ filhos: $A$, $B$ e $C$.

a. O evento "$A$ é mais velho que $B$" é independente de "$A$ é mais velho que $C$"?

:::

* Intuitivamente: 

  Não, pois $A$ ser mais velho que $B$ torna mais provável que $A$ seja mais velho que $C$.

::: {.rmdbox latex=1}

b. Qual a probabilidade de que $A$ é mais velho que $B$, dado que $A$ é mais velho que $C$?

:::

* Queremos achar $P(A > B \mid A > C)$.

* Esta probabilidade é igual a 

  $$
  \frac{P(A > B,  A > C)}{P(A > C)}
  $$

* O numerador é a probabilidade de $A$ ser o mais velho.

* Se todas as $6$ ordens de nascimento tiverem a mesma probabilidade,

  $$
  P(A > B,  A > C) = 2/6 = 1/3
  $$

* O denominador é

  $$
  P(A > C) = 3/6 = 1/2
  $$

* Daí, $P(A > B \mid A > C) = \frac{1/3}{1/2} = \frac23$.

* De fato, a probabilidade [condicional]{.hl} $P(A > B \mid A > C) = 2/3$ é [maior]{.hl} do que a probabilidade [não-condicional]{.hl} $P(A > B) = 1/2$.


### 31 {-}

::: {.rmdbox latex=1}

Um evento pode ser independente de si mesmo?

:::

* Chamando este evento de $A$, é preciso que

  $$
  P(A \cap A) = P(A) = P(A) \cdot P(A)
  $$

* Isto só é possível se $P(A) = 0$ ou se $P(A) = 1$.


### 32. Dados de Efron {-}

::: {.rmdbox latex=1}

Considere $4$ dados não-padrão (*dados de Efron*), cujos lados são rotulados da seguinte forma (cada lado tem a mesma probabilidade):

$$
\begin{aligned}
  A &: 4, 4, 4, 4, 0, 0 \\
  B &: 3, 3, 3, 3, 3, 3 \\
  C &: 6, 6, 2, 2, 2, 2 \\
  D &: 5, 5, 5, 1, 1, 1
\end{aligned}
$$

Cada dado é lançado uma vez. Cada letra representa o resultado do dado correspondente.

a. Ache $P(A > B)$, $P(B > C)$, $P(C > D)$, e $P(D > A)$.

:::

* Eventos equivalentes:

  $$
  \begin{aligned}
    A > B &\iff A = 4 \\
    B > C &\iff C = 2 \\
    C > D &\iff C = 6 \cup (C = 2 \cap D = 1) \\
    D > A & \iff D = 5 \cup (D = 1\cap A = 0)
  \end{aligned}
  $$

* $P(A > B) = 2/3$.

* $P(B > C) = 2/3$.

* $P(C > D) = 1/3 + 2/3 \cdot 1/2 = 2/3$.

* $P(D > A) = 1/2 + 1/2 \cdot 2/3 = 2/3$.

::: {.rmdbox latex=1}

b. O evento $A > B$ é independente de $B > C$?

   O evento $B > C$ é independente de $C > D$?

:::

* Sim: 

  $$
  \begin{aligned}
  P(A > B \cap B > C) &= P(A = 4) \cdot P(C = 2) \\
  &= P(A > B) \cdot P(B > C)
  \end{aligned}
  $$

  Intuitivamente: como o resultado de $B$ não importa para $A > B$ nem para $B > C$, os eventos são independentes.

* Não:

  $$
  \begin{aligned}
    P(B > C \cap C > D) 
    &= P(C = 2 \cap [C = 6 \cup (C = 2 \cap D = 1)]) \\
    &= P((C = 2 \cap C = 6) \cup (C = 2 \cap D = 1)) \\
    &= P(C = 2 \cap D = 1) \\
    &= 2/3 \cdot 1/2 \\
    &= 1/3
  \end{aligned}
  $$

  mas
  
  $$
  P(B > C) \cdot P(C > D) = 4/9
  $$


### 33 {-}


### 35. Xadrez {-}

::: {.rmdbox latex=1}

* Você vai jogar $2$ partidas de xadrez contra um adversário desconhecido. 

* O nível do seu adversário pode ser novato, intermediário, ou avançado, com probabilidades iguais.

* As probabilidades de você vencer uma partida são, dependendo do nível do adversário, respectivamente, $90\%$, $50\%$, e $30\%$.

a. Qual a probabilidade de você vencer a primeira partida?

b. Parabéns, você venceu a primeira partida. Dada esta informação, qual a probabilidade de que você também vença a segunda partida (suponha que, [dado o nível do seu adversário]{.hl}, os resultados das partidas são independentes)?

c. Explique a diferença entre 

   1. supor que os resultados das partidas são independentes, e
   
   2. supor que os resultados das partidas são independentes, dado o nível do seu adversário.
   
   Qual destas suposições parece mais razoável? Por quê?

:::

* Antes de mais nada, vamos definir os eventos:

  $$
  \begin{aligned}
    N &= \text{o adversário é novato} \\
    I &= \text{o adversário é intermediário} \\
    A &= \text{o adversário é avançado} \\
    V_1 &= \text{você vence a primeira partida} \\
    V_2 &= \text{você vence a segunda partida} 
  \end{aligned}
  $$

* O enunciado dá as probabilidades

  $$
  \begin{aligned}
  P(N) &= 1/3 \\
  P(I) &= 1/3 \\
  P(A) &= 1/3 \\
  P(V_1 \mid N) &= 9/10 \\
  P(V_1 \mid I) &= 5/10 \\
  P(V_1 \mid A) &= 3/10
  \end{aligned}
  $$

* Para resolver (a), basta usar probabilidade total, condicionando sobre o nível do adversário:

  $$
  \begin{aligned}
  P(V_1) 
  &= 
  P(V_1 \mid N) \cdot P(N) \;+\;
  P(V_1 \mid I) \cdot P(I) \;+\;
  P(V_1 \mid A) \cdot P(A)
  \\
  &= 
  \frac{9}{10} \cdot \frac{1}{3} + 
  \frac{5}{10} \cdot \frac{1}{3} + 
  \frac{3}{10} \cdot \frac{1}{3} \\
  &= 
  \frac{1}{3} \cdot \left(
  \frac{9}{10} + 
  \frac{5}{10} + 
  \frac{3}{10} \right) \\
  &=
  \frac{17}{30}
  \end{aligned}
  $$

  Faz sentido. Como as probabilidades dos níveis possíveis do adversário são iguais, a probabilidade de vencer é [a média aritmética]{.hl} das probabilidades de vencer contra cada nível.
  
  Se as probabilidades dos níveis do adversário fossem diferentes, seria a [média ponderada.]{.hl}
  
* Para (b), queremos calcular $P(V_2 \mid V_1)$.

  Dizer que $V_1$ e $V_2$ são independentes [dado o nível do adversário]{.hl} é dizer
  
  $$
  P(V_2 \mid V_1, N) = P(V_1 \mid V_2, N) = P(V_2 \mid N) = P(V_1 \mid N)
  $$

  e analogamente para probabilidades condicionadas a $I$ e a $A$.
  
  Ou seja, dado um nível específico do adversário, saber que $V_1$ ocorreu não altera a probabilidade de $V_2$ ocorrer, e vice-versa.
  
  Vamos calcular $P(V_2 \mid V_1)$ usando probabilidade total, condicionando ao nível:
  
  $$
  \begin{aligned}
  \underbrace{P(V_2 \mid V_1, N) \cdot P(N \mid V_1)}_{\text{novato}}
  \;+\;
  \underbrace{P(V_2 \mid V_1, I) \cdot P(I \mid V_1)}_{\text{intermediário}}
  \;+\;
  \underbrace{P(V_2 \mid V_1, A) \cdot P(A \mid V_1)}_{\text{avançado}}
  \end{aligned}
  $$

  Para o lado esquerdo de cada produto, a independência condicional diz que
  
  \begin{alignat*}{3}
  P(V_2 \mid V_1, N) &= P(V_1 \mid N) &= 9/10 \\
  P(V_2 \mid V_1, I) &= P(V_1 \mid I) &= 5/10 \\
  P(V_2 \mid V_1, A) &= P(V_1 \mid A) &= 3/10
  \end{alignat*}

  Para o lado direito de cada produto, usamos Bayes. Todas as probabilidades envolvidas já foram calculadas.
  
  Novato:
  
  $$
  \begin{aligned}
  P(N \mid V_1) 
  &=
  \frac{P(V_1 \mid N) \cdot P(N)}{P(V_1)}
  \\
  &= \frac{9/10 \cdot 1/3}{17/30}
  \\
  &= \frac{9}{17}
  \end{aligned}
  $$

  Intermediário:
  
  $$
  \begin{aligned}
  P(I \mid V_1) 
  &=
  \frac{P(V_1 \mid I) \cdot P(I)}{P(V_1)}
  \\
  &= \frac{5/10 \cdot 1/3}{17/30}
  \\
  &= \frac{5}{17}
  \end{aligned}
  $$
  
  Avançado:
  
  $$
  \begin{aligned}
  P(A \mid V_1) 
  &=
  \frac{P(V_1 \mid A) \cdot P(A)}{P(V_1)}
  \\
  &= \frac{3/10 \cdot 1/3}{17/30}
  \\
  &= \frac{3}{17}
  \end{aligned}
  $$

  A resposta final é
  
  $$
  \frac{9}{10} \cdot \frac{9}{17} \;+\;
  \frac{5}{10} \cdot \frac{5}{17} \;+\;
  \frac{3}{10} \cdot \frac{3}{17}
  \;=\;
  \frac{`r (81 + 25 + 9)/5`}{`r 170/5`}
  $$

* Para responder (c):

  Dizer que $V_1$ e $V_2$ são [incondicionalmente]{.hl} independentes seria dizer que 
  
  $$
  P(V_2 \mid V_1) = P(V_2)
  $$

  Ainda mais, como o nível do adversário não muda de uma partida para outra, teríamos também 
  
  $$
  P(V_2) = P(V_1)
  $$

  Ou seja, cada partida seria uma prova de Bernoulli com a mesma probabilidade de sucesso.
  
  Considerando independência [condicional]{.hl}, saber que vencemos a primeira partida nos dá informação sobre o nível do adversário, e esta informação é considerada para calcular a probabilidade de vencer a segunda partida.
  
  De fato, usando independência condicional, temos
  
  $$
  P(V_1) \approx `r 17/30`
  $$
  
  e
  
  $$
  P(V_2 \mid V_1) \approx `r 23/34`
  $$
  

### 36. [Paradoxo de Berkson](https://en.wikipedia.org/wiki/Berkson%27s_paradox) {-}

::: {.rmdbox latex=1}

[Se]{.hl} 

* $A$ e $B$ são independentes, e

* $P(A \cap B) > 0$, e

* $P(A \cup B) < 1$, e

* $C = A \cup B$

[então]{.hl} $A$ e $B$ são condicionalmente dependentes, dado $C$, com

$$
P(A \mid B, C) < P(A \mid C)
$$

Exemplo: universidade admite candidatos que são bons jogadores de basquete ($A$) ou que são bons em Matemática ($B$) --- [supondo que estes são eventos independentes, o que é meio duvidoso]{.hl}.^[Na verdade, em vez de independência entre $A$ e $B$, basta que um evento atrapalhe o outro para termos o paradoxo. Em termos da [nossa medida de independência $I$](#i), basta $0< I < 1$.] 

:::

* De $P(A \cap B) > 0$, temos que $P(A) > 0$ e que $P(B) > 0$.

* Daí, $P(C) = P(A \cup B) > 0$.

* Para o lado esquerdo:

  $$
  \begin{aligned}
  P(A \mid B, C) 
  &= \frac{P(A \cap B \cap C)}{P(B \cap C)} \\
  &= \frac{P(A \cap B)}{P(B)} \\
  &= \frac{P(A)P(B)}{P(B)} \\
  &= P(A)
  \end{aligned}
  $$

* Para o lado direito:

  $$
  \begin{aligned}
  P(A \mid C) 
  &= \frac{P(A \cap C)}{P(C)} \\
  &= \frac{P(A)}{P(C)} \\
  &= \frac{P(A)}{P(A \cup B)} 
  \end{aligned}
  $$

* Como o denominador $P(A \cup B) < 1$, esta probabilidade é maior do que $P(A)$.


### 37 {-}

::: {.rmdbox latex=1}

* Quem tem a doença $D_1$ ou a doença $D_2$ (ou ambas) tem o sintoma estranho $W$.

* $D_1$ e $D_2$ são independentes, com $P(D_j) = p_j$, e com $q_j = 1 - p_j$. 

* $0 < p_j < 1$.

* Uma pessoa sadia tem o sintoma $W$ com probabilidade $w_0$.

:::

::: {.rmdbox latex=1}

a. Achar $P(W)$.

:::

* Por probabilidade total:

  $$
  \begin{aligned}
  P(W) 
  &= P(W \mid D_1 \cup D_2) \cdot P(D_1 \cup D_2) +
  P(W \mid \neg(D_1 \cup D_2)) \cdot P(\neg(D_1 \cup D_2)) \\
  &= 1 \cdot (p_1 + p_2 - p_1p_2) + w_0 \cdot (1 - p_1 - p_2 + p_1p_2) \\
  &= p_1 + p_2 - p_1p_2 + w_0q_1q_2 
  \end{aligned}
  $$

::: {.rmdbox latex=1}

b. Achar $P(D_1 \mid W)$, $P(D_2 \mid W)$, e $P(D_1 \cap D_2 \mid W)$.

:::

* Por Bayes:

  $$
  \begin{aligned}
    P(D_1 \mid W) 
    &= \frac{P(W \mid D_1) \cdot P(D_1)}{P(W)} \\
    &= \frac{1 \cdot p_1}{p_1 + p_2 - p_1p_2 + w_0q_1q_2} \\
    &= \frac{p_1}{p_1 + p_2 - p_1p_2 + w_0q_1q_2}
  \end{aligned}
  $$

* Analogamente,

  $$
  P(D_2 \mid W) = \frac{p_2}{p_1 + p_2 - p_1p_2 + w_0q_1q_2}
  $$

* Finalmente,

  $$
  \begin{aligned}
  P(D_1 \cap D_2 \mid W)
  &= \frac{P(D_1 \cap D_2 \cap W)}{P(W)} \\
  &= \frac{P(D_1 \cap D_2)}{P(W)} & (\text{pois }D_1 \cap D_2 \subseteq W)\\
  &= \frac{p_1p_2}{p_1 + p_2 - p_1p_2 + w_0q_1q_2}
  \end{aligned}
  $$

::: {.rmdbox latex=1}

c. $D_1$ e $D_2$ são condicionalmente independentes, dado $W$?

:::

* Basta verificar se

  $$
  P(D_1 \mid W) \cdot P(D_2 \mid W) = P(D_1 \cap D_2 \mid W)
  $$

* Isto equivale a

  $$
  \frac{p_1p_2}{(p_1 + p_2 - p_1p_2 + w_0q_1q_2)^2} = 
  \frac{p_1p_2}{p_1 + p_2 - p_1p_2 + w_0q_1q_2}
  $$

* [Esta igualdade só é verdade se]{.hl}

  1. $w_0 = 0$ e $P(D_1 \cup D_2) = 0$ (o que é proibido pelo enunciado). Ninguém estaria doente, e ninguém teria o sintoma.
  
     ou
  
  2. $P(D_1 \cup D_2) = 1$. Aqui, todos estariam doentes, e todos teriam o sintoma. 
  
* Lembramos que 

  $$
  w_0 = P(W \mid \neg(D_1 \cup D_2)) = 
  \frac{P(W \cap \neg(D_1 \cup D_2))}{P(\neg(D_1 \cup D_2))}
  $$

* No caso (1) acima, $w_0 = P(W) = 0$, e não faz mais sentido condicionar sobre $W$.

* No caso (2) acima, $P(\neg(D_1 \cup D_2)) = 0$, e a própría definição de $w_0$ deixa de fazer sentido.

  
::: {.rmdbox latex=1}

d. Suponha que $w_0 = 0$. Neste caso, $D_1$ e $D_2$ são condicionalmente independentes, dado $W$?

:::

* Por causa do discutido no item (c), vamos supor que $$0 < P(D_1 \cup D_2) < 1$$ para que possamos condicionar sobre $W$ e para que a definição de $w_0$ faça sentido.

* Como no item (c), verificamos se

  $$
  P(D_1 \mid W) \cdot P(D_2 \mid W) = P(D_1 \cap D_2 \mid W)
  $$

* Que equivale a 

  $$
  \frac{p_1p_2}{(p_1 + p_2 - p_1p_2)^2} = 
  \frac{p_1p_2}{p_1 + p_2 - p_1p_2}
  $$

* Isto é impossível, se $0 < P(D_1 \cup D_2) < 1$.

* Intuitivamente, $D_1$ e $D_2$ seriam [condicionalmente dependentes]{.hl}, dado $W$, pois, dado que uma pessoa tem o sintoma $W$, saber que ela não tem a doença $D_1$ imediatamente nos diz que ela tem a doença $D_2$.

::: {.rmdnote latex=1}

Quando $w_0 = 0$ e $0 < P(D_1 \cup D_2) < 1$, a consequência é que 

$$
D_1 \cup D_2 = W
$$
como eventos.

Daí, com as outras condições do enunciado, temos uma instância do [paradoxo de Berkson](#paradoxo-de-berkson), com $A = D_1$ e $B = D_2$.

:::


### 38. Naïve Bayes {-}

::: {.rmdbox latex=1}

* Temos uma lista de $100$ palavras.

* Evento $W_j = {}$ a palavra $j$ aparece no *email*.

* Evento $\text{spam} = {}$ o *email* é *spam*.

* $p = P(\text{spam})$.

* $p_j = P(W_j \mid \text{spam})$.

* $r_j = P(W_j \mid \neg \text{spam})$.

* A *naïveté* do algoritmo consiste nas seguintes suposições --- não-realistas, mas úteis:

  * Os $W_j$ são condicionalmente independentes, dado $\text{spam}$.
  
  * Os $W_j$ são condicionalmente independentes, dado $\neg \text{spam}$.

* Um novo *email* é recebido. Contém as palavras $23$, $64$, e $65$, e nenhuma das outras.

* Vamos chamar de $\vec W$ a lista de eventos

  $$
  \begin{array}{l}
  \neg W_1, \ldots, \neg W_{22}, \\
  W_{23},\\ 
  \neg W_{24}, \ldots, \neg W_{63},\\    
  W_{64}, W_{65},\\ 
  \neg W_{66}, \ldots, \neg W_{100}
  \end{array}
  $$
  
* Calcular $P\left( \text{spam} \;\middle|\; \vec W \right)$.

:::

* Por Bayes:

  $$
  P\left( \text{spam} \;\middle|\; \vec W \right) = 
  \frac{P\left(\vec W \;\middle|\; \text{spam} \right)}
  {P\left( \vec W  \right)}
  $$

* Com a suposição *naïve*, podemos multiplicar as probabilidades condicionais:

  $$
  P\left(\vec W\;\middle|\; \text{spam} \right) =
  p_{23} \cdot p_{64} \cdot p_{65} \cdot
  \!\!\!\!\!\!\!\!\!
  \prod_{
    \begin{array}{c}
    1 \leq j \leq 100. \\
    j \not\in \{ 23, 64, 65 \}
    \end{array}
  }
  \!\!\!\!\!\!\!
  (1 - p_j)
  $$
  
  [Vamos chamar este valor de $m$.]{.hl}
  
* Para calcular $P\left( \vec W \right)$, usamos probabilidade total:

  $$
  \begin{aligned}
  P\left( \vec W \right) 
  &= 
    P\left(\vec W \;\middle|\; \text{spam} \right) 
    \cdot P(\text{spam})
    \;+\;
    P\left(\vec W \;\middle|\; \neg\text{spam} \right) 
    \cdot P(\neg\text{spam})
  \\
  &=
    m \cdot p \;+\; m' \cdot (1 - p)
  \end{aligned}
  $$
  
  onde, de maneira análoga ao cálculo de $m$,
  
  $$
  m' = 
    r_{23} \cdot r_{64} \cdot r_{65} \cdot
  \!\!\!\!\!\!\!\!\!
  \prod_{
    \begin{array}{c}
    1 \leq j \leq 100. \\
    j \not\in \{ 23, 64, 65 \}
    \end{array}
  }
  \!\!\!\!\!\!\!
  (1 - r_j)
  $$
  
* O valor procurado é, então,

  $$
  P\left( \text{spam} \;\middle|\; \vec W \right) 
  = 
  \frac{P\left(\vec W \;\middle|\; \text{spam} \right)}
  {P\left( \vec W  \right)}
  = \frac{mp}{mp + m'(1 - p)}
  $$
  
  
